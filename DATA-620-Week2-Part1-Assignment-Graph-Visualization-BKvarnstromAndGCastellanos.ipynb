{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08680957-f61a-4ab9-b415-e3905ebdf2df",
   "metadata": {},
   "source": [
    "# Week 2 Part 1 Assignment: Graph Visualization\n",
    "\n",
    "Team:\n",
    "Gabriel Castellanos, Beshkia Kvarnstrom\n",
    "\n",
    "\n",
    "This week's assignment is to:   1. Load a graph database of your choosing from a text file or other source. If you take a large network dataset from the web (such as from https://snap.stanford.edu/data/), please feel free at this point to load just a small subset of the nodes and edges.  \n",
    "\n",
    "2. Create basic analysis on the graph, including the graphâ€™s diameter, and at least one other metric of your choosing. You may either code the functions by hand (to build your intuition and insight), or use functions in an existing package.  \n",
    "\n",
    "3. Use a visualization tool of your choice (Neo4j, Gephi, etc.) to display information.  \n",
    "\n",
    "4. Please record a short video (~ 5 minutes), and submit a link to the video as part of your homework submission.   \n",
    "\n",
    "You may work in a small group on this project. Parts one and two should be posted to GitHub and submitted in your assignment link by end of day September 12th. Parts 3 and 4 should be in your video presentation. We may display some of the results in our Meet-up on September 13th "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e50275-10de-4eb7-bdaf-54a89e8922f3",
   "metadata": {},
   "source": [
    "For this assignment we are using the 'Social circles: Facebook'.\n",
    "\n",
    "This dataset consists of 'circles' (or 'friends lists') from Facebook. Facebook data was collected from survey participants using this Facebook app. The dataset includes node features (profiles), circles, and ego networks.\n",
    "\n",
    "the dataset was taken from: https://snap.stanford.edu/data/ego-Facebook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777bb835-7754-430d-8867-8afeec55187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd489b8a-7dbb-484b-bae5-3c3b18930589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph database from the text file\n",
    "url = \"https://raw.githubusercontent.com/BeshkiaKvarnstrom/DATA-620-Web-Analytics-Assignments/main/Data/facebook_combined.txt\"\n",
    "\n",
    "# Send an HTTP GET request to the GitHub raw file URL\n",
    "response = requests.get(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa911d1-ffc0-44b9-adfd-8cdc2ad6c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Access the content of the response\n",
    "    file_content = response.text\n",
    "\n",
    "    # Write the file content to a local file\n",
    "    with open(\"facebook_combined.txt\", \"w\") as file:\n",
    "        file.write(file_content)\n",
    "\n",
    "    # Read the local file as a graph\n",
    "    graph = nx.read_edgelist(\"facebook_combined.txt\", create_using=nx.Graph())\n",
    "\n",
    "    # Limit the number of nodes and edges\n",
    "    max_nodes = 1000  # Maximum number of nodes to load\n",
    "    max_edges = 3000  # Maximum number of edges to load\n",
    "    graph = graph.subgraph(list(graph.nodes())[:max_nodes])\n",
    "    graph = graph.edge_subgraph(list(graph.edges())[:max_edges])\n",
    "\n",
    "    # Check if the graph is empty\n",
    "    if graph.number_of_nodes() == 0 or graph.number_of_edges() == 0:\n",
    "        print(\"Graph is empty. Cannot perform calculations.\")\n",
    "    else:\n",
    "        # Print the number of nodes in the graph\n",
    "        print(\"The Number of nodes is:\", graph.number_of_nodes())\n",
    "\n",
    "        # Print the number of edges in the graph\n",
    "        print(\"The Number of edges is:\", graph.number_of_edges())\n",
    "\n",
    "        # Calculate clustering coefficient\n",
    "        try:\n",
    "            # Calculate another metric of your choosing (e.g., average clustering coefficient)\n",
    "            clustering_coefficient = nx.average_clustering(graph)\n",
    "            print(\"The Average clustering coefficient:\", clustering_coefficient)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Graph has no triangles. Clustering coefficient is undefined.\")\n",
    "\n",
    "        # Calculate average shortest path length\n",
    "        try:\n",
    "            # Choose another metric to analyze\n",
    "            # Here, we'll use the average shortest path length\n",
    "            average_shortest_path_length = nx.average_shortest_path_length(graph)\n",
    "            print(\n",
    "                \"The average shortest path length of the graph is:\",\n",
    "                average_shortest_path_length,\n",
    "            )\n",
    "        except nx.NetworkXPointlessConcept:\n",
    "            print(\"Graph has no paths. Average shortest path length is undefined.\")\n",
    "\n",
    "        # Check if the graph is connected\n",
    "        if nx.is_connected(graph):\n",
    "            # Calculate the diameter of the graph\n",
    "            diameter = nx.diameter(graph)\n",
    "            print(\"The diameter of the Graph is:\", diameter)\n",
    "        else:\n",
    "            print(\"Graph is not connected. Diameter calculation is undefined.\")\n",
    "\n",
    "            # Calculate the diameter of the largest connected component\n",
    "            largest_component = max(nx.connected_components(graph), key=len)\n",
    "            subgraph = graph.subgraph(largest_component)\n",
    "            diameter = nx.diameter(subgraph)\n",
    "            print(\"The diameter of the largest connected component is:\", diameter)\n",
    "\n",
    "        degree_centrality = nx.degree_centrality(graph)\n",
    "        highest_degree_nodes = sorted(\n",
    "            degree_centrality, key=degree_centrality.get, reverse=True\n",
    "        )[:5]\n",
    "\n",
    "        print(\"Nodes with highest degree centrality:\")\n",
    "        for node in highest_degree_nodes:\n",
    "            print(\"Node:\", node, \"Degree Centrality:\", degree_centrality[node])\n",
    "\n",
    "\n",
    "        # Visualize the graph\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        nx.draw_networkx(\n",
    "            graph,\n",
    "            with_labels=True,\n",
    "            node_color=\"#26004d\",\n",
    "            node_size=600,\n",
    "            font_weight=\"bold\",\n",
    "            edge_color=\"#e6ccff\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        plt.show(block=True)  # Keep the figure window open\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the Graph Database file. Status code:\", response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
